{"expand":"renderedFields,names,schema,transitions,operations,editmeta,changelog","id":"12503056","self":"https://issues.apache.org/jira/rest/api/latest/issue/12503056","key":"MAHOUT-646","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/images/icons/issuetypes/bug.png","name":"Bug","subtask":false},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310751","id":"12310751","key":"MAHOUT","name":"Mahout","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310751&avatarId=10011","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310751&avatarId=10011","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310751&avatarId=10011","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310751&avatarId=10011"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/13060","id":"13060","description":"Apache Mahout","name":"Mahout"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12315255","id":"12315255","description":"","name":"0.5","archived":false,"released":true,"releaseDate":"2011-05-27"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2011-03-31 19:03:35.613","customfield_12312323":null,"customfield_12310420":"9415","customfield_12312320":null,"customfield_12310222":"10002_*:*_1_*:*_267627154_*|*_1_*:*_1_*:*_95105_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"customfield_12312120":null,"customfield_12312121":null,"resolutiondate":"2011-04-03T20:40:39.356+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312326":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312324":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAHOUT-646/watchers","watchCount":0,"isWatching":false},"created":"2011-03-31T18:18:37.114+0000","priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/4","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/minor.png","name":"Minor","id":"4"},"labels":[],"customfield_12312333":null,"customfield_12312334":null,"customfield_12310310":"0.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12312330":null,"customfield_12311120":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12315255","id":"12315255","description":"","name":"0.5","archived":false,"released":true,"releaseDate":"2011-05-27"}],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=srowen","name":"srowen","emailAddress":"srowen at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=srowen&avatarId=10104","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=srowen&avatarId=10104","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=srowen&avatarId=10104","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=srowen&avatarId=10104"},"displayName":"Sean Owen","active":true},"customfield_12312337":null,"customfield_12312338":null,"updated":"2011-05-21T03:18:46.807+0000","customfield_12312335":null,"customfield_12312336":null,"customfield_12311720":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Complete"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312152","id":"12312152","name":"Classification","description":"Issues related to classification"}],"timeoriginalestimate":null,"description":"When I tried to run the Wikipedia example on EMR with all the categories existing in the Wikipedia dump, I got this error :\r\n\r\norg.apache.hadoop.ipc.RemoteException: org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException: failed to create file /yatter.tagger/wikipedia/input/_temporary/_attempt__0000_r_000000_0/part-r-00000 for DFSClient_attempt_201103292134_0010_r_000000_0 on client 10.240.10.157 because current leaseholder is trying to recreate file.\r\n    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1045)\r\n    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:981)\r\n    at org.apache.hadoop.hdfs.server.namenode.NameNode.create(NameNode.java:377)\r\n    at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)\r\n\r\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\r\n    at java.lang.reflect.Method.invoke(Method.java:597)\r\n    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)\r\n    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:961)\r\n    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:957)\r\n    at java.security.AccessController.doPrivileged(Native Method)\r\n    at javax.security.auth.Subject.doAs(Subject.java:396)\r\n    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:955)\r\n\r\n    at org.apache.hadoop.ipc.Client.call(Client.java:740)\r\n    at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)\r\n    at $Proxy1.create(Unknown Source)\r\n\r\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\r\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\r\n    at java.lang.reflect.Method.invoke(Method.java:597)\r\n    at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)\r\n    at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)\r\n    at $Proxy1.create(Unknown Source)\r\n    at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.<init>(DFSClient.java:2709)\r\n    at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:491)\r\n    at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:195)\r\n    at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:524)\r\n    at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:505)\r\n    at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:412)\r\n    at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:128)\r\n    at org.apache.mahout.classifier.bayes.MultipleTextOutputFormat.getBaseRecordWriter(MultipleTextOutputFormat.java:41)\r\n    at org.apache.mahout.classifier.bayes.MultipleOutputFormat$1.write(MultipleOutputFormat.java:81)\r\n    at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.write(ReduceTask.java:517)\r\n    at org.apache.hadoop.mapreduce.TaskInputOutputContext.write(TaskInputOutputContext.java:80)\r\n    at org.apache.mahout.classifier.bayes.WikipediaDatasetCreatorReducer.reduce(WikipediaDatasetCreatorReducer.java:35)\r\n    at org.apache.mahout.classifier.bayes.WikipediaDatasetCreatorReducer.reduce(WikipediaDatasetCreatorReducer.java:28)\r\n    at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:176)\r\n    at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:575)\r\n    at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:412)\r\n    at org.apache.hadoop.mapred.Child.main(Child.java:170)\r\n\r\norg.apache.hadoop.ipc.RemoteException: java.io.IOException: failed to create file /yatter.tagger/wikipedia/input/_temporary/_attempt__0000_r_000000_0/part-r-00000 on client 10.240.10.157 either because the filename is invalid or the file exists\r\n    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1092)\r\n    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:981)\r\n    at org.apache.hadoop.hdfs.server.namenode.NameNode.create(NameNode.java:377)\r\n    at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)\r\n\r\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\r\n    at java.lang.reflect.Method.invoke(Method.java:597)\r\n    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)\r\n    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:961)\r\n    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:957)\r\n    at java.security.AccessController.doPrivileged(Native Method)\r\n    at javax.security.auth.Subject.doAs(Subject.java:396)\r\n    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:955)\r\n\r\n    at org.apache.hadoop.ipc.Client.call(Client.java:740)\r\n    at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)\r\n    at $Proxy1.create(Unknown Source)\r\n\r\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\r\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\r\n    at java.lang.reflect.Method.invoke(Method.java:597)\r\n    at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)\r\n    at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)\r\n    at $Proxy1.create(Unknown Source)\r\n    at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.<init>(DFSClient.java:2709)\r\n    at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:491)\r\n    at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:195)\r\n    at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:524)\r\n    at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:505)\r\n    at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:412)\r\n    at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:128)\r\n    at org.apache.mahout.classifier.bayes.MultipleTextOutputFormat.getBaseRecordWriter(MultipleTextOutputFormat.java:41)\r\n    at org.apache.mahout.classifier.bayes.MultipleOutputFormat$1.write(MultipleOutputFormat.java:81)\r\n    at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.write(ReduceTask.java:517)\r\n    at org.apache.hadoop.mapreduce.TaskInputOutputContext.write(TaskInputOutputContext.java:80)\r\n    at org.apache.mahout.classifier.bayes.WikipediaDatasetCreatorReducer.reduce(WikipediaDatasetCreatorReducer.java:35)\r\n    at org.apache.mahout.classifier.bayes.WikipediaDatasetCreatorReducer.reduce(WikipediaDatasetCreatorReducer.java:28)\r\n    at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:176)\r\n    at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:575)\r\n    at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:412)\r\n    at org.apache.hadoop.mapred.Child.main(Child.java:170)\r\n\r\n    4 more :\r\n   org.apache.hadoop.ipc.RemoteException: java.io.IOException: failed to create file /yatter.tagger/wikipedia/input/_temporary/_attempt__0000_r_000000_0/part-r-00000 on client 10.240.10.157 either because the filename is invalid or the file exists","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12312024":null,"customfield_12312340":null,"aggregatetimeestimate":null,"customfield_12312022":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12310921":null,"customfield_12310920":"22773","summary":"Cannot run Wikipedia example on Amazon Elastic MapReduce (EMR)","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vivrass","name":"vivrass","emailAddress":"mprovencher86 at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Martin Provencher","active":true},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vivrass","name":"vivrass","emailAddress":"mprovencher86 at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Martin Provencher","active":true},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"startAt":0,"maxResults":7,"total":7,"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12503056/comment/13014115","id":"13014115","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vivrass","name":"vivrass","emailAddress":"mprovencher86 at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Martin Provencher","active":true},"body":"To fix it, I've applied this patch :\r\n\r\n===================================================================\r\n--- examples/src/main/java/org/apache/mahout/classifier/bayes/WikipediaDatasetCreatorDriver.java\t(revision 1087334)\r\n+++ examples/src/main/java/org/apache/mahout/classifier/bayes/WikipediaDatasetCreatorDriver.java\t(working copy)\r\n@@ -185,7 +185,7 @@\r\n     //TODO: job.setNumMapTasks(100);\r\n     job.setInputFormatClass(XmlInputFormat.class);\r\n     job.setReducerClass(WikipediaDatasetCreatorReducer.class);\r\n-    job.setOutputFormatClass(WikipediaDatasetCreatorOutputFormat.class);\r\n+    //job.setOutputFormatClass(WikipediaDatasetCreatorOutputFormat.class);\r\n     \r\n     FileInputFormat.setInputPaths(job, new Path(input));\r\n     Path outPath = new Path(output);","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=vivrass","name":"vivrass","emailAddress":"mprovencher86 at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Martin Provencher","active":true},"created":"2011-03-31T18:20:12.211+0000","updated":"2011-03-31T18:20:12.211+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12503056/comment/13014144","id":"13014144","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=srowen","name":"srowen","emailAddress":"srowen at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=srowen&avatarId=10104","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=srowen&avatarId=10104","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=srowen&avatarId=10104","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=srowen&avatarId=10104"},"displayName":"Sean Owen","active":true},"body":"OK. Commenting out the line means the output format is not being used at all. Is that valid? (I don't know.)\r\nBut in any event there seems to be an actual problem, here:\r\n\r\n{{...\r\nat org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:128)\r\nat org.apache.mahout.classifier.bayes.MultipleTextOutputFormat.getBaseRecordWriter(MultipleTextOutputFormat.java:41)\r\nat org.apache.mahout.classifier.bayes.MultipleOutputFormat$1.write(MultipleOutputFormat.java:81)\r\nat org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.write(ReduceTask.java:517)\r\nat org.apache.hadoop.mapreduce.TaskInputOutputContext.write(TaskInputOutputContext.java:80)\r\nat org.apache.mahout.classifier.bayes.WikipediaDatasetCreatorReducer.reduce(WikipediaDatasetCreatorReducer.java:35)\r\n...}}\r\n\r\nIt's this attempt to create a file here that's resulting in the \"already being created\" exception. Anyone have any ideas here?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=srowen","name":"srowen","emailAddress":"srowen at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=srowen&avatarId=10104","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=srowen&avatarId=10104","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=srowen&avatarId=10104","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=srowen&avatarId=10104"},"displayName":"Sean Owen","active":true},"created":"2011-03-31T19:03:35.613+0000","updated":"2011-03-31T19:03:35.613+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12503056/comment/13014179","id":"13014179","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mat_kelcey","name":"mat_kelcey","emailAddress":"matthew dot kelcey at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mat_kelcey&avatarId=10321","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mat_kelcey&avatarId=10321","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mat_kelcey&avatarId=10321","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mat_kelcey&avatarId=10321"},"displayName":"Mat Kelcey","active":true},"body":"Could this be anything to do with running on EMR?\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mat_kelcey","name":"mat_kelcey","emailAddress":"matthew dot kelcey at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=mat_kelcey&avatarId=10321","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=mat_kelcey&avatarId=10321","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=mat_kelcey&avatarId=10321","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=mat_kelcey&avatarId=10321"},"displayName":"Mat Kelcey","active":true},"created":"2011-03-31T20:09:24.294+0000","updated":"2011-03-31T20:09:24.294+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12503056/comment/13014526","id":"13014526","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=srowen","name":"srowen","emailAddress":"srowen at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=srowen&avatarId=10104","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=srowen&avatarId=10104","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=srowen&avatarId=10104","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=srowen&avatarId=10104"},"displayName":"Sean Owen","active":true},"body":"Could be... but somehow I doubt it. I note that in MAHOUT-614 we fixed up an apparent problem with this class. The change might have uncovered a different issue (or, er, actually messed it up in a different way).\r\n\r\nOne way forward is to fix it. Another way is to delete it. I say that's an option since WikipediaDatasetCreatorOutputFormat is the one and only class which depends on two classes copied and modified from Hadoop. Going forward we'd want to go back to the main-line version somehow.\r\n\r\nAnd if removing use of this custom output format doesn't \"hurt\", as the issue implies, well, why not just remove it?\r\n\r\nBut the question is... is it really just as well to let this dump to a sequence file or does that defeat the purpose? Robin?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=srowen","name":"srowen","emailAddress":"srowen at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=srowen&avatarId=10104","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=srowen&avatarId=10104","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=srowen&avatarId=10104","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=srowen&avatarId=10104"},"displayName":"Sean Owen","active":true},"created":"2011-04-01T11:55:28.147+0000","updated":"2011-04-01T11:55:28.147+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12503056/comment/13015071","id":"13015071","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=robinanil","name":"robinanil","emailAddress":"robinanil at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=robinanil&avatarId=14747","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=robinanil&avatarId=14747","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=robinanil&avatarId=14747","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=robinanil&avatarId=14747"},"displayName":"Robin Anil","active":true},"body":"Unfortunately Bayes classifier reads from a text input format. And I wanted to split the output of different categories into multiple files for the wikipedia example, which btw is not necessary for Bayes, it reads of all the files anyways. Dropping it wouldnt create any problems. Just have to update all tutorials and references which mention that fact.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=robinanil","name":"robinanil","emailAddress":"robinanil at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=robinanil&avatarId=14747","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=robinanil&avatarId=14747","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=robinanil&avatarId=14747","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=robinanil&avatarId=14747"},"displayName":"Robin Anil","active":true},"created":"2011-04-02T19:43:24.506+0000","updated":"2011-04-02T19:43:24.506+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12503056/comment/13015208","id":"13015208","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=srowen","name":"srowen","emailAddress":"srowen at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=srowen&avatarId=10104","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=srowen&avatarId=10104","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=srowen&avatarId=10104","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=srowen&avatarId=10104"},"displayName":"Sean Owen","active":true},"body":"OK done.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=srowen","name":"srowen","emailAddress":"srowen at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=srowen&avatarId=10104","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=srowen&avatarId=10104","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=srowen&avatarId=10104","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=srowen&avatarId=10104"},"displayName":"Sean Owen","active":true},"created":"2011-04-03T20:40:39.365+0000","updated":"2011-04-03T20:40:39.365+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12503056/comment/13015233","id":"13015233","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","emailAddress":"jira at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true},"body":"Integrated in Mahout-Quality #715 (See [https://hudson.apache.org/hudson/job/Mahout-Quality/715/])\r\n    MAHOUT-646 Just output one text file for Wikipedia example to avoid some bug in MultipleOutputFormat subclass\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","emailAddress":"jira at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true},"created":"2011-04-03T22:16:33.628+0000","updated":"2011-04-03T22:16:33.628+0000"}]},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAHOUT-646/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i049b3:"}}