{"expand":"renderedFields,names,schema,transitions,operations,editmeta,changelog","id":"12612976","self":"https://issues.apache.org/jira/rest/api/latest/issue/12612976","key":"MAHOUT-1103","fields":{"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/images/icons/issuetypes/bug.png","name":"Bug","subtask":false},"timespent":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12310751","id":"12310751","key":"MAHOUT","name":"Mahout","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12310751&avatarId=10011","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12310751&avatarId=10011","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12310751&avatarId=10011","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12310751&avatarId=10011"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/13060","id":"13060","description":"Apache Mahout","name":"Mahout"}},"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12320153","id":"12320153","description":"The release will stabilize core components, improve performances and adds new streaming algorithms. Unmaintained code is getting killed as part of this","name":"0.8","archived":false,"released":true,"releaseDate":"2013-07-25"}],"aggregatetimespent":null,"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12310220":"2012-10-22 14:56:47.46","customfield_12312323":null,"customfield_12310420":"250327","customfield_12312320":null,"customfield_12310222":"3_*:*_1_*:*_74743587_*|*_1_*:*_1_*:*_19791547233_*|*_5_*:*_1_*:*_0","customfield_12312321":null,"customfield_12312120":null,"customfield_12312121":null,"resolutiondate":"2013-06-09T12:41:36.380+0000","workratio":-1,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312326":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312324":null,"customfield_12312325":null,"lastViewed":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAHOUT-1103/watchers","watchCount":7,"isWatching":false},"created":"2012-10-22T14:16:45.578+0000","priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.png","name":"Major","id":"3"},"labels":["clusterpp"],"customfield_12312333":null,"customfield_12312334":null,"customfield_12310310":"3.0","customfield_12312331":null,"customfield_12312332":null,"timeestimate":null,"aggregatetimeoriginalestimate":null,"customfield_12312330":null,"customfield_12311120":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12320153","id":"12320153","description":"The release will stabilize core components, improve performances and adds new streaming algorithms. Unmaintained code is getting killed as part of this","name":"0.8","archived":false,"released":true,"releaseDate":"2013-07-25"}],"issuelinks":[],"customfield_12312339":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gsingers","name":"gsingers","emailAddress":"gsingers at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Grant Ingersoll","active":true},"customfield_12312337":null,"customfield_12312338":null,"updated":"2014-02-03T08:06:13.640+0000","customfield_12312335":null,"customfield_12312336":null,"customfield_12311720":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Complete"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12312151","id":"12312151","name":"Clustering","description":"Bugs related to any of the clustering packages"}],"timeoriginalestimate":null,"description":"After running kmeans clustering on a set of ~3M points, clusterpp fails to populate directories for some clusters, no matter what k is.\r\n\r\nI've tested this on my data with k = 300, 250, 150, 100, 50, 25, 10, 5, 2\r\n\r\nEven with k=2 only one cluster directory was created. For each reducer that fails to produce directories there is an empty part-r-* file in the output directory.\r\n\r\nHere is my command sequence for the k=2 run:\r\n{noformat}bin/mahout kmeans -i ssvd2/USigma -c 2clusters/init-clusters -o 2clusters/pca-clusters -dm org.apache.mahout.common.distance.TanimotoDistanceMeasure -cd 0.05 -k 2 -x 15 -cl\r\n\r\nbin/mahout clusterdump -i 2clusters/pca-clusters/clusters-*-final -o 2clusters.txt\r\n\r\nbin/mahout clusterpp -i 2clusters/pca-clusters -o 2clusters/bottom{noformat} \r\n\r\nThe output of clusterdump shows two clusters: VL-3742464 and VL-3742466 containing 2585843 and 1156624 points respectively.\r\n\r\nDiscussion on the user mailing list suggested that this might be caused by the default hadoop hash partitioner. The hashes of these two clusters aren't identical, but they are close. Putting both cluster names into a Text and caling hashCode() gives:\r\nVL-3742464 -> -685560454\r\nVL-3742466 -> -685560452\r\n\r\nFinally, when running with \"-xm sequential\", everything performs as expected.","customfield_10010":null,"timetracking":{},"customfield_12312026":null,"customfield_12312023":null,"customfield_12312024":null,"customfield_12312340":null,"aggregatetimeestimate":null,"customfield_12312022":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12310921":null,"customfield_12310920":"61641","summary":"clusterpp is not writing directories for all clusters","creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmolek","name":"mmolek","emailAddress":"mpmolek at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Molek","active":true},"subtasks":[],"customfield_12310291":null,"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmolek","name":"mmolek","emailAddress":"mpmolek at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Molek","active":true},"customfield_12310290":null,"aggregateprogress":{"progress":0,"total":0},"customfield_12311024":null,"environment":null,"customfield_12311020":null,"duedate":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"comment":{"startAt":0,"maxResults":36,"total":36,"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13481408","id":"13481408","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=paritoshranjan","name":"paritoshranjan","emailAddress":"paritoshranjan5 at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=paritoshranjan&avatarId=12534","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=paritoshranjan&avatarId=12534","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=paritoshranjan&avatarId=12534","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=paritoshranjan&avatarId=12534"},"displayName":"Paritosh Ranjan","active":true},"body":"\"I've tested this on my data with k = 300, 250, 150, 100, 50, 25, 10, 5, 2\"\r\n\r\nSince its not working for even two clusters, I don't see any problem due to the Partitioner. The input here looks like the output of SSVD. There has been problems reported earlier also, where SSVD output was creating problems in clustering.\r\n\r\nCan your try kmeans + clusterpp without performing SSVD on the vectors? I suspect this to be the problem for now, but we will have to test it. \r\n\r\nThe sequential and mapreduce versions are completely differernt implementations, so, its normal to have a bug in one version which is not present in the second version.\r\n\r\nPlease update once you test it.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=paritoshranjan","name":"paritoshranjan","emailAddress":"paritoshranjan5 at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=paritoshranjan&avatarId=12534","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=paritoshranjan&avatarId=12534","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=paritoshranjan&avatarId=12534","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=paritoshranjan&avatarId=12534"},"displayName":"Paritosh Ranjan","active":true},"created":"2012-10-22T14:56:47.460+0000","updated":"2012-10-22T14:56:47.460+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13481433","id":"13481433","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmolek","name":"mmolek","emailAddress":"mpmolek at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Molek","active":true},"body":"Yes, I am clustering on ssvd output. I will try again with the vectors directly from seq2sparse and update once I'm done.\r\n\r\nI was just reading up on the way the HashPartitioner works though, and I do think it is part of the issue. HashPartitioner uses the following logic to determine what partition a key belongs to: int partition = (key.hashCode() & Integer.MAX_VALUE) % numReduceTasks;\r\n\r\nThat yields a partition of 0 for both VL-3742464 and VL-3742466. If however, they were named VL-0 and VL-1, they would be properly split up by the HashPartitioner. I think if clusters were always named VL-i where 0<=i<k, then there would not be an issue. Dealing with this weird naming scheme (which I don't know the origin of since I'm not familiar with the inner workings of kmeans) seems to be the issue.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmolek","name":"mmolek","emailAddress":"mpmolek at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Molek","active":true},"created":"2012-10-22T15:20:55.522+0000","updated":"2012-10-22T15:23:22.882+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13481544","id":"13481544","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=paritoshranjan","name":"paritoshranjan","emailAddress":"paritoshranjan5 at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=paritoshranjan&avatarId=12534","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=paritoshranjan&avatarId=12534","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=paritoshranjan&avatarId=12534","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=paritoshranjan&avatarId=12534"},"displayName":"Paritosh Ranjan","active":true},"body":"Instead of changing the nomenclature of clusters, we should create a partitioner which solves the problem ( if the problem is in partitioner ). \r\n\r\nBy changing the nomenclature of the clusters, we will be fixing the bug just for this particular case. In case, someone creates as many as 3742464 clusters ( assume ), or more, then again the same problem will rise. So, we should fix it at a generic level.\r\n\r\nLooking forward for your tests without SVD. As I said earlier, also try to use a better Partitioner. The partitioner can be changed in postProcessMR method of ClusterOutputPostProcessorDriver class. \r\n\r\nYou can read this page https://cwiki.apache.org/MAHOUT/how-to-contribute.html to see how to get code and generate patches.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=paritoshranjan","name":"paritoshranjan","emailAddress":"paritoshranjan5 at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=paritoshranjan&avatarId=12534","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=paritoshranjan&avatarId=12534","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=paritoshranjan&avatarId=12534","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=paritoshranjan&avatarId=12534"},"displayName":"Paritosh Ranjan","active":true},"created":"2012-10-22T17:46:04.202+0000","updated":"2012-10-22T17:46:04.202+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13481546","id":"13481546","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dlyubimov","name":"dlyubimov","emailAddress":"dlyubimov at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Dmitriy Lyubimov","active":true},"body":"bq. Since its not working for even two clusters, I don't see any problem due to the Partitioner. The input here looks like the output of SSVD. There has been problems reported earlier also, where SSVD output was creating problems in clustering.\r\n\r\n\r\nWhat issues? Can you be more specific? \r\n\r\nThe only discussion i am aware of was with Pat and he was having problem using embedded style and with the fact that there were no --USigma output available at that time. \r\n\r\nI am not aware of any issues in the HEAD. he should be able to use --pca true option and if it retains enough variance (i.e. fairly rapid spectrum decay in the first 100-ish values) he should be fine at least with euclidean coordinates clustering. \r\n\r\nif he looks at cosine similarities for topical clustering (aka LSA) he doesn't need --pca option.\r\n\r\nEither way it is not a problem of SSVD but a problem of the approach.\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dlyubimov","name":"dlyubimov","emailAddress":"dlyubimov at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Dmitriy Lyubimov","active":true},"created":"2012-10-22T17:50:17.633+0000","updated":"2012-10-22T17:52:04.048+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13481550","id":"13481550","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmolek","name":"mmolek","emailAddress":"mpmolek at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Molek","active":true},"body":"{quote}he should be able to use --pca true option and if it retains enough variance (i.e. fairly rapid spectrum decay in the first 100-ish values) he should be fine at least with euclidean coordinates clustering.\r\n\r\nif he looks at cosine similarities for topical clustering (aka LSA) he doesn't need --pca option.{quote}\r\n\r\nHi Dmitriy, sorry for going a little off topic here, but could you elaborate on this? I've been experimenting with using either cosine or tanimoto distance on the USigma output of ssvd with -pca true. Are those not appropriate distance measures for the -pca output?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmolek","name":"mmolek","emailAddress":"mpmolek at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Molek","active":true},"created":"2012-10-22T17:55:43.779+0000","updated":"2012-10-22T17:55:43.779+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13481552","id":"13481552","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dlyubimov","name":"dlyubimov","emailAddress":"dlyubimov at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Dmitriy Lyubimov","active":true},"body":"btw Tanimoto distance suggests he actually wants LSA topics, not pure PCA (euclidean). Further on, usually output U is taken for this purpose. \r\n\r\nI would suggest the author to prototype with R on a document subset first to make sure his pipeline yields result he expects. Unfortunately we don't have an easy way to convert DRM to R data sets (yet), hopefully some work will be done at some point to bridge that gap.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dlyubimov","name":"dlyubimov","emailAddress":"dlyubimov at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Dmitriy Lyubimov","active":true},"created":"2012-10-22T17:57:01.937+0000","updated":"2012-10-22T17:57:48.335+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13481557","id":"13481557","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dlyubimov","name":"dlyubimov","emailAddress":"dlyubimov at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Dmitriy Lyubimov","active":true},"body":"bq. Hi Dmitriy, sorry for going a little off topic here, but could you elaborate on this? I've been experimenting with using either cosine or tanimoto distance on the USigma output of ssvd with -pca true. Are those not appropriate distance measures for the -pca output?\r\n\r\nI'll reply on user list, that way somebody will surely try to correct me since i have been doing straightforward LSA only.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dlyubimov","name":"dlyubimov","emailAddress":"dlyubimov at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Dmitriy Lyubimov","active":true},"created":"2012-10-22T17:59:16.197+0000","updated":"2012-10-22T18:00:07.530+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13481626","id":"13481626","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmolek","name":"mmolek","emailAddress":"mpmolek at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Molek","active":true},"body":"I've finished a test with k=25 on input directly from seq2sparse, and the problem has persisted. I'm pretty sure it's because of the way the HashPartitioner is splitting up the \"VL-*\" Text keys, and doesn't have anything to do with the input vectors (whether they came from seq2sparse or ssvd).\r\n\r\nI can't start working on a patch right now, but I will check back when I have some free time and see what I can do if there hasn't been any progress.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmolek","name":"mmolek","emailAddress":"mpmolek at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Molek","active":true},"created":"2012-10-22T18:54:13.868+0000","updated":"2012-10-22T18:54:13.868+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13481680","id":"13481680","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=paritoshranjan","name":"paritoshranjan","emailAddress":"paritoshranjan5 at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=paritoshranjan&avatarId=12534","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=paritoshranjan&avatarId=12534","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=paritoshranjan&avatarId=12534","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=paritoshranjan&avatarId=12534"},"displayName":"Paritosh Ranjan","active":true},"body":"Dmitriy, I was talking about the issue where VectorIds were being lost. That was not a ssvd problem, but the way ssvd + kmeans was used. I faintly remember that, so I just wanted to make sure that the same problem is not there.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=paritoshranjan","name":"paritoshranjan","emailAddress":"paritoshranjan5 at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=paritoshranjan&avatarId=12534","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=paritoshranjan&avatarId=12534","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=paritoshranjan&avatarId=12534","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=paritoshranjan&avatarId=12534"},"displayName":"Paritosh Ranjan","active":true},"created":"2012-10-22T19:19:40.219+0000","updated":"2012-10-22T19:19:40.219+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13481702","id":"13481702","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dlyubimov","name":"dlyubimov","emailAddress":"dlyubimov at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Dmitriy Lyubimov","active":true},"body":"You mean, propagation of names in NamedVector to products of U? yes this has been addressed at the same time as --USigma, current trunk should be good.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=dlyubimov","name":"dlyubimov","emailAddress":"dlyubimov at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Dmitriy Lyubimov","active":true},"created":"2012-10-22T19:32:12.665+0000","updated":"2012-10-22T19:32:12.665+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13483390","id":"13483390","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=paritoshranjan","name":"paritoshranjan","emailAddress":"paritoshranjan5 at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=paritoshranjan&avatarId=12534","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=paritoshranjan&avatarId=12534","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=paritoshranjan&avatarId=12534","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=paritoshranjan&avatarId=12534"},"displayName":"Paritosh Ranjan","active":true},"body":"Dmitriy - yes, I think it was the same error. \r\n\r\nMatt - I have created a partitioner and applied it at ClusterOutputPostProcessorDriver assuming the valid cluster Ids are the latest and sequential i.e. ids will be VL-8543 to VL 8563 if 20 unique clusters are there. The attached test case demonstrates that it will work for this scenario.\r\n\r\nIf you want, you can try this patch on trunk, and check whether it works or not. I am not sure about it, as I still need to figure out the nomenclature of relevant cluster Ids.  ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=paritoshranjan","name":"paritoshranjan","emailAddress":"paritoshranjan5 at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=paritoshranjan&avatarId=12534","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=paritoshranjan&avatarId=12534","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=paritoshranjan&avatarId=12534","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=paritoshranjan&avatarId=12534"},"displayName":"Paritosh Ranjan","active":true},"created":"2012-10-24T16:54:56.998+0000","updated":"2012-10-24T16:54:56.998+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13489762","id":"13489762","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=paritoshranjan","name":"paritoshranjan","emailAddress":"paritoshranjan5 at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=paritoshranjan&avatarId=12534","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=paritoshranjan&avatarId=12534","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=paritoshranjan&avatarId=12534","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=paritoshranjan&avatarId=12534"},"displayName":"Paritosh Ranjan","active":true},"body":"I tried to test cluster post processing with Junit but the problem is while running through Junits ( standalone mode ), the numpartitions is always 1. So, the partitioner does not behave in the way it should. \r\n\r\nI will try running it on a cluster to test the results. \r\n\r\nI think the current approach to post process is highly dependent on cluster ids + partitioner which is somehow not correct. Any change in clustering approach will have an impact on cluster post processing. I will also think of another ways to solve it.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=paritoshranjan","name":"paritoshranjan","emailAddress":"paritoshranjan5 at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=paritoshranjan&avatarId=12534","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=paritoshranjan&avatarId=12534","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=paritoshranjan&avatarId=12534","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=paritoshranjan&avatarId=12534"},"displayName":"Paritosh Ranjan","active":true},"created":"2012-11-02T21:23:34.894+0000","updated":"2012-11-02T21:23:56.901+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13598990","id":"13598990","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmolek","name":"mmolek","emailAddress":"mpmolek at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Molek","active":true},"body":"I've implemented an idea for this that works regardless of what the cluster ids are. It's in a separate class right now, but if you like the idea, I can refactor it as a patch to the current clusterpp code.\r\n\r\nI made a class similar to o.a.m.clustering.topdown.postprocessor.ClusterCountReader, called ClusterIDReader. Given a clustering output directory, it reads all the cluster ids and returns a list containing the cluster ids.\r\n\r\nTo actually process the data, I run a MapReduce job over the clusterdPoints ouput directory. In the mapper's setup function, the list of clusters is obtained from ClusterIDReader, and a HashMap is constructed. The HashMap maps each cluster id to an int from 0 to k-1. The mapper emits each clustered vector with its new key 0 to k-1.\r\n\r\nThere are k reducers, one for each cluster, and each reducer uses ClusterIDReader to reverse the clusterID mapping that was created by the mappers. This allows the original cluster ids to be preserved at the end of the job. Once the job is done, the movePartFilesToRespectiveDirectories method works as before to move the part files to correctly named directories. \r\n\r\nBecause the intermediate keys are guaranteed to be an unbroken sequence of ints from 0 to k-1, I think the hash partitioner will always send the vectors from each cluster to exactly one reducer (assuming there are k reducers).\r\n\r\nWould you like a version of this as a patch?\r\n\r\n ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmolek","name":"mmolek","emailAddress":"mpmolek at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Molek","active":true},"created":"2013-03-11T17:02:12.170+0000","updated":"2013-03-11T17:02:52.991+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13672209","id":"13672209","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gsingers","name":"gsingers","emailAddress":"gsingers at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Grant Ingersoll","active":true},"body":"[~dlyubimov] or [~mmolek] any updates on this?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gsingers","name":"gsingers","emailAddress":"gsingers at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Grant Ingersoll","active":true},"created":"2013-06-01T19:30:24.815+0000","updated":"2013-06-01T19:30:24.815+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13672657","id":"13672657","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gsingers","name":"gsingers","emailAddress":"gsingers at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Grant Ingersoll","active":true},"body":"I can reproduce this.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gsingers","name":"gsingers","emailAddress":"gsingers at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Grant Ingersoll","active":true},"created":"2013-06-02T19:49:39.584+0000","updated":"2013-06-02T19:49:39.584+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13672658","id":"13672658","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gsingers","name":"gsingers","emailAddress":"gsingers at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Grant Ingersoll","active":true},"body":"This seems like a flat out bug in the ClusterPP, since it says it is supposed to write separate directories, so it doesn't seem to me like we need to add new classes here, but instead should fix the bug.  Still looking.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gsingers","name":"gsingers","emailAddress":"gsingers at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Grant Ingersoll","active":true},"created":"2013-06-02T20:02:36.172+0000","updated":"2013-06-02T20:02:36.172+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13672669","id":"13672669","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gsingers","name":"gsingers","emailAddress":"gsingers at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Grant Ingersoll","active":true},"body":"Hmm, so this works in Sequential mode, but not in MapReduce mode","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gsingers","name":"gsingers","emailAddress":"gsingers at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Grant Ingersoll","active":true},"created":"2013-06-02T20:25:11.181+0000","updated":"2013-06-02T20:25:11.181+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13672718","id":"13672718","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gsingers","name":"gsingers","emailAddress":"gsingers at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Grant Ingersoll","active":true},"body":"It has an assumption in the code that each cluster id ends up in a different part file by the fact the number of reducers is set to the number of clusters which is supposed to mean that there should be one output part file per reducer (i.e. per cluster id), but that isn't happening, at least in the simple testing I'm doing using pseudo M/R mode using data generated from.  Can someone test this on a real Hadoop cluster, as I don't have access to one right at the moment?  At least in the non-cluster env, the work around is to run in sequential mode.\r\n\r\n\r\n{quote}\r\nbin/mahout org.apache.mahout.clustering.syntheticcontrol.meanshift.Job -x 25 -cd 5 -t1 50 -t2 10 -dm org.apache.mahout.common.distance.EuclideanDistanceMeasure -i /path/content/synthetic_control.data  -ow -o output -cl\r\n{quote}\r\nand\r\n{quote}\r\n... org.apache.mahout.clustering.topdown.postprocessor.ClusterOutputPostProcessorDriver -i output -o output/postMR\r\n{quote}","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gsingers","name":"gsingers","emailAddress":"gsingers at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Grant Ingersoll","active":true},"created":"2013-06-02T23:32:33.089+0000","updated":"2013-06-02T23:32:33.089+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13672760","id":"13672760","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmolek","name":"mmolek","emailAddress":"mpmolek at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Molek","active":true},"body":"{quote}\r\nThis seems like a flat out bug in the ClusterPP, since it says it is supposed to write separate directories, so it doesn't seem to me like we need to add new classes here, but instead should fix the bug.\r\n{quote}\r\n\r\nWell yes, it is a bug. I've reproduced it on a real cluster (that's what lead me to origianlly post this jira). The problem is that the distributed clusterpp job assumes that the hash partitioner will correctly distribute the cluster ids, one to each reducer. That would only happen in the situation where the clusters are numbered 1 to k or some other convenient numbering. That is rarely, if ever, the case.\r\n\r\nThe only way I could think to get this working is to temporarily remap the cluster ids to a more convenient numbering that would play well with the hash partitioner. See my earlier comment for the exact way I went about that. I don't think any small tweaks will fix the current distributed code. As far as I can tell, you either need to temporarily change the cluster numbering, or write some new partitioner (and I can't think of a way to do it with a paritioner). Maybe there's some third option, but I can't think of one.\r\n\r\nI'm happy to try coming up with a patch for the way I've solved it, if you want to go about it that way.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmolek","name":"mmolek","emailAddress":"mpmolek at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Molek","active":true},"created":"2013-06-03T02:28:12.275+0000","updated":"2013-06-03T02:28:59.988+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13672836","id":"13672836","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gsingers","name":"gsingers","emailAddress":"gsingers at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Grant Ingersoll","active":true},"body":"bq. Well yes, it is a bug. I've reproduced it on a real cluster (that's what lead me to origianlly post this jira)\r\n\r\n:-)  Yeah, just confirming it.  We get a lot of non-bugs reported.  I wonder if we used to just sequentially dole out cluster ids and that changed w/ the clustering refactoring.\r\n\r\n{quote}That would only happen in the situation where the clusters are numbered 1 to k or some other convenient numbering. That is rarely, if ever, the case.\r\nThe only way I could think to get this working is to temporarily remap the cluster ids to a more convenient numbering that would play well with the hash partitioner{quote}\r\n\r\nI don't know a lot about partitioners just yet and that makes me think they might be heavy handed here, but it occurs to me that we can take advantage of that the number of clusters is small and during setup simply load up the cluster id map and create the \"convenient numbering\" for writing during the reduce phase to 0 - n-1 (where n is the number of clusters).\r\n\r\nThen, in the {code}movePartFilesToRespectiveDirectories{code} we should get renamed appropriately.\r\n\r\nWould that work?\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gsingers","name":"gsingers","emailAddress":"gsingers at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Grant Ingersoll","active":true},"created":"2013-06-03T05:42:17.465+0000","updated":"2013-06-03T05:42:17.465+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13672981","id":"13672981","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gsingers","name":"gsingers","emailAddress":"gsingers at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Grant Ingersoll","active":true},"body":"OK, I read up on partitioners and I'd agree, Matt, this is effectively hadoop's way of doing what I proposed and doesn't pollute the M/R code, so I'm going to go forward w/ your patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gsingers","name":"gsingers","emailAddress":"gsingers at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Grant Ingersoll","active":true},"created":"2013-06-03T10:35:03.542+0000","updated":"2013-06-03T10:35:03.542+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13673071","id":"13673071","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gsingers","name":"gsingers","emailAddress":"gsingers at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Grant Ingersoll","active":true},"body":"Matt, out of curiosity, what's your use case for the clusterpp?  [~robinanil] and I are both looking at this code and wondering why it is useful to separate out the clusters into their own directory.  MAHOUT-843 doesn't shed any light on it for us either.\r\n\r\nAlso, I don't think the current patch partitions correctly.  For instance, try a numPartitions of 2 and cluster ids of 153 and 53.  Then, 10^1 means you get 153 % 10 and 53 % 10 both = 3 and you have a collision.  So, I think I'm back to my original thought, which is in the mappers and reducers, we need to load up the cluster ids and just map it there.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gsingers","name":"gsingers","emailAddress":"gsingers at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Grant Ingersoll","active":true},"created":"2013-06-03T12:36:46.773+0000","updated":"2013-06-03T12:36:46.773+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13673119","id":"13673119","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmolek","name":"mmolek","emailAddress":"mpmolek at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Molek","active":true},"body":"{quote}\r\nYeah, just confirming it. We get a lot of non-bugs reported. I wonder if we used to just sequentially dole out cluster ids and that changed w/ the clustering refactoring.\r\n{quote}\r\n\r\nSorry, no problem. I just wanted to make sure nothing was getting overlooked since this thread is getting rather long.\r\n\r\n{quote}\r\nwhich is in the mappers and reducers, we need to load up the cluster ids and just map it there.\r\n{quote}\r\n\r\nThat's exactly what I've gotten working on my own project. It's not submitted here yet as a patch because the first version of it that I made was just to see if it would work, and isn't in mahout's code style. I think there was a different earlier patch from Paritosh which is the patch currently attached. My code is pretty simple. I can submit a patch in the next couple of days once I find a little free time.\r\n\r\n{quote}\r\nMatt, out of curiosity, what's your use case for the clusterpp? Robin Anil and I are both looking at this code and wondering why it is useful to separate out the clusters into their own directory.\r\n{quote}\r\n\r\nFor me, the value in separating the clusters out into their own directories is that it makes it very easy to lauch further mahout jobs against the contents of an individual cluster. I cluster, separate the results, and then launch new jobs against each clusterpp output directory. I find it pretty useful.\r\n\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmolek","name":"mmolek","emailAddress":"mpmolek at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Molek","active":true},"created":"2013-06-03T13:58:40.811+0000","updated":"2013-06-03T13:58:40.811+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13673143","id":"13673143","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gsingers","name":"gsingers","emailAddress":"gsingers at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Grant Ingersoll","active":true},"body":"bq. I can submit a patch in the next couple of days once I find a little free time\r\n\r\nAwesome.  Please do.  I've got momentum on this issue and towards 0.8, so if you can soon, that would be great.  Don't worry about codestyle, I can take care of that and any other pieces. If you have the gist of it working, then you'll save me a bit of time.\r\n\r\nbq. different earlier patch\r\n\r\nAh, my confusion...  Sorry about that.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gsingers","name":"gsingers","emailAddress":"gsingers at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Grant Ingersoll","active":true},"created":"2013-06-03T14:10:33.235+0000","updated":"2013-06-03T14:10:33.235+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13677163","id":"13677163","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gsingers","name":"gsingers","emailAddress":"gsingers at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Grant Ingersoll","active":true},"body":"[~mmolek] Any luck on the patch?  I'd like to close this out before 0.8 if possible.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gsingers","name":"gsingers","emailAddress":"gsingers at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Grant Ingersoll","active":true},"created":"2013-06-06T15:54:01.940+0000","updated":"2013-06-06T15:54:01.940+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13677261","id":"13677261","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmolek","name":"mmolek","emailAddress":"mpmolek at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Molek","active":true},"body":"I've been held up with some local problems with running tests. When building mahout with testing enabled, I'm getting lots of out of memory errors that I haven't figured out yet. This is happening to me on a clean checkout of the trunk, so it's nothing I've modified. It must just be something weird with my local environment.\r\n\r\nSo, apologies for not being able to fully test this. It does build with -DskipTests=true though, and it worked fine when testing it on some real data just now.\r\n\r\nAs I was typing this up I just remembered that I changed the keys from Texts to IntWritables, since int is the only type of ID a ClusterWritable can have. That probably makes the map/reduce implementation inconsistent with the way the sequential method does it though. To get identical output to the sequential method, the reducer just needs to output a Text with the cluster id, instead of an IntWritable with the cluster id like is does in my patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmolek","name":"mmolek","emailAddress":"mpmolek at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Molek","active":true},"created":"2013-06-06T17:24:37.561+0000","updated":"2013-06-06T17:24:37.561+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13677269","id":"13677269","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=srowen","name":"srowen","emailAddress":"srowen at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=srowen&avatarId=10104","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=srowen&avatarId=10104","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=srowen&avatarId=10104","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=srowen&avatarId=10104"},"displayName":"Sean Owen","active":true},"body":"A-ha, I bet that's related to my last change to reduce the memory allowed during tests, in order to avoid a different kind of out-of-memory problem. It succeeds for me locally on Java 7. Try upping \"-Xmx512m\" in pom.xml to \"-Xmx768M\". What version of Java? if it's 6, maybe try \"-XX:+UseCompressedOops\" instead / as well? Hopefully there is a middle ground that works here.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=srowen","name":"srowen","emailAddress":"srowen at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=srowen&avatarId=10104","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=srowen&avatarId=10104","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=srowen&avatarId=10104","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=srowen&avatarId=10104"},"displayName":"Sean Owen","active":true},"created":"2013-06-06T17:29:17.167+0000","updated":"2013-06-06T17:29:17.167+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13677328","id":"13677328","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmolek","name":"mmolek","emailAddress":"mpmolek at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Molek","active":true},"body":"Fount it, I think. Increasing the -Xmx option wasn't the solution, but the problem was related to the the parallel testing configuration. I have 6 cores, and the forkCount in pom.xml is set to 1.5C. 9 parallel tests was more than could fit into available memory on my computer. It would've taken me a while to figure out that I should look there, so thanks for the suggestion.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmolek","name":"mmolek","emailAddress":"mpmolek at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Molek","active":true},"created":"2013-06-06T18:13:04.433+0000","updated":"2013-06-06T18:13:04.433+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13677335","id":"13677335","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=srowen","name":"srowen","emailAddress":"srowen at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=srowen&avatarId=10104","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=srowen&avatarId=10104","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=srowen&avatarId=10104","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=srowen&avatarId=10104"},"displayName":"Sean Owen","active":true},"body":"Hmm, but would that cause an OutOfMemoryError? that implies that there was not enough heap in each JVM. The problem you describe is what I saw too; too much heap from too many JVMs causing a load of swapping. The JVMs themselves were fine; they had plenty of heap. It's just that the whole machine was slowing to a crawl due to swapping. Reducing forkCount would still leave each JVM with the same heap, and if it's not sufficient, it would still fail.\r\n\r\nI can however imagine that the current setting is a little tight, and when the machine slows due to swapping, it makes the GC give up due to excessive time in collection, earlier. Then the swapping could induce `OutOfMemoryError`, maybe.\r\n\r\nBut if you just mean you saw too much swapping... how much RAM do you have? I would think 8GB would kind of work.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=srowen","name":"srowen","emailAddress":"srowen at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=srowen&avatarId=10104","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=srowen&avatarId=10104","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=srowen&avatarId=10104","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=srowen&avatarId=10104"},"displayName":"Sean Owen","active":true},"created":"2013-06-06T18:19:17.627+0000","updated":"2013-06-06T18:19:17.627+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13677346","id":"13677346","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmolek","name":"mmolek","emailAddress":"mpmolek at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Molek","active":true},"body":"Sorry, I was too general with my terminology. It wasn't actually an OutOfMemoryError. The actual error message was one I hadn't come across before:\r\n{quote}\r\nThere is insufficient memory for the Java Runtime Environment to continue.\r\nNative memory allocation (malloc) failed to allocate 857408 bytes for Chunk::new\r\n{quote}\r\n\r\nI have 8GB of ram, so I was surprised that I didn't have room for 9 512MB VM's to run, but lowering the forkCount did fix the problem for me.\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmolek","name":"mmolek","emailAddress":"mpmolek at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Molek","active":true},"created":"2013-06-06T18:28:50.684+0000","updated":"2013-06-06T18:29:04.561+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13677389","id":"13677389","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=srowen","name":"srowen","emailAddress":"srowen at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=srowen&avatarId=10104","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=srowen&avatarId=10104","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=srowen&avatarId=10104","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=srowen&avatarId=10104"},"displayName":"Sean Owen","active":true},"body":"512MB of heap can mean quite a bit more than that used by the JVM. Thread stacks, native code memory allocations, buffers, and other stuff adds up to maybe 25% more in overhead. Do you have swap off? then all your other OS stuff is resident in RAM too and that could take a lot.\r\n\r\nThere's some argument to turn down fork to one per core, although that probably leaves cores underutilized as many JVMs will be waiting on I/O at any given time. With 1C, core tests take 10.5 minutes for me (2 cores, 4 virtual cores). It's 9.3 minutes with 1.5C.\r\n\r\nHmm, is it better to turn this down to make sure the tests run out of the box for more people, and leave it to those with big machines to manually tune this upwards? Or vice versa. The speed difference is about 15%. The number of people for whom it would fail now is... I don't know. It failed for 3 of us before my change, now down to 1. Might be reasonable to think 5-10% of users won't be able to run the tests as is?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=srowen","name":"srowen","emailAddress":"srowen at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=srowen&avatarId=10104","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=srowen&avatarId=10104","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=srowen&avatarId=10104","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=srowen&avatarId=10104"},"displayName":"Sean Owen","active":true},"created":"2013-06-06T19:07:42.973+0000","updated":"2013-06-06T19:07:42.973+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13677665","id":"13677665","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmolek","name":"mmolek","emailAddress":"mpmolek at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Molek","active":true},"body":"I have 8GB of swap, so I'm confused by the memory error. When nothing else is running, I'm only using 1.1GB of memory and 0% swap, so I should've been ok with 9 concurrent tests. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=mmolek","name":"mmolek","emailAddress":"mpmolek at gmail dot com","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Matt Molek","active":true},"created":"2013-06-06T23:38:20.677+0000","updated":"2013-06-06T23:38:20.677+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13678727","id":"13678727","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gsingers","name":"gsingers","emailAddress":"gsingers at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Grant Ingersoll","active":true},"body":"Matt, can you check this iteration on your patch?  That being said, it doesn't work for me running the MR job locally when testing on a small data set.  Would be nice to get this self contained somehow in a small unit test.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gsingers","name":"gsingers","emailAddress":"gsingers at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Grant Ingersoll","active":true},"created":"2013-06-08T11:13:56.277+0000","updated":"2013-06-08T11:13:56.277+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13678753","id":"13678753","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gsingers","name":"gsingers","emailAddress":"gsingers at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Grant Ingersoll","active":true},"body":"The MapReduce portion of this will never function correctly in Hadoop LocalMode.  I've added a printout to the Driver to note this in my next patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=gsingers","name":"gsingers","emailAddress":"gsingers at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Grant Ingersoll","active":true},"created":"2013-06-08T15:57:15.210+0000","updated":"2013-06-08T15:57:15.210+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13679049","id":"13679049","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","emailAddress":"jira at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true},"body":"Integrated in Mahout-Quality #2063 (See [https://builds.apache.org/job/Mahout-Quality/2063/])\r\n    MAHOUT-1103: properly partition the data for MapReduce (Revision 1491191)\r\n\r\n     Result = SUCCESS\r\ngsingers : \r\nFiles : \r\n* /mahout/trunk/core/src/main/java/org/apache/mahout/clustering/topdown/postprocessor/ClusterCountReader.java\r\n* /mahout/trunk/core/src/main/java/org/apache/mahout/clustering/topdown/postprocessor/ClusterOutputPostProcessor.java\r\n* /mahout/trunk/core/src/main/java/org/apache/mahout/clustering/topdown/postprocessor/ClusterOutputPostProcessorDriver.java\r\n* /mahout/trunk/core/src/main/java/org/apache/mahout/clustering/topdown/postprocessor/ClusterOutputPostProcessorMapper.java\r\n* /mahout/trunk/core/src/main/java/org/apache/mahout/clustering/topdown/postprocessor/ClusterOutputPostProcessorReducer.java\r\n* /mahout/trunk/core/src/main/java/org/apache/mahout/vectorizer/DictionaryVectorizer.java\r\n* /mahout/trunk/core/src/main/java/org/apache/mahout/vectorizer/SparseVectorsFromSequenceFiles.java\r\n* /mahout/trunk/core/src/main/java/org/apache/mahout/vectorizer/term/TFPartialVectorReducer.java\r\n* /mahout/trunk/core/src/main/java/org/apache/mahout/vectorizer/tfidf/TFIDFPartialVectorReducer.java\r\n* /mahout/trunk/examples/bin/cluster-reuters.sh\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","emailAddress":"jira at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true},"created":"2013-06-09T13:15:30.071+0000","updated":"2013-06-09T13:15:30.071+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12612976/comment/13679274","id":"13679274","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","emailAddress":"jira at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true},"body":"Integrated in Mahout-Quality #2071 (See [https://builds.apache.org/job/Mahout-Quality/2071/])\r\n    MAHOUT-1103: properly partition the data for MapReduce - code cleanup based on review, instantiate Maps with Maps.newHashMap() (Revision 1491329)\r\n\r\n     Result = SUCCESS\r\nsmarthi : \r\nFiles : \r\n* /mahout/trunk/core/src/main/java/org/apache/mahout/clustering/topdown/postprocessor/ClusterOutputPostProcessor.java\r\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","emailAddress":"jira at apache dot org","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true},"created":"2013-06-10T03:13:11.342+0000","updated":"2013-06-10T03:13:11.342+0000"}]},"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/MAHOUT-1103/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12311820":"0|i0ax4v:"}}